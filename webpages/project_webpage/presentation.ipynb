{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reimplementing the Transformer to learn more about the Attention mechanism\n",
    "## Baptiste Amato, Alexis Durocher, Gabriel Hurtado, Alexandre Jouandin, Vincent Marois\n",
    "\n",
    "Spring 2019 CS 7643 Deep Learning Class Project\n",
    "Georgia Tech"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TEMPLATE HERE: \n",
    "https://www.cc.gatech.edu/classes/AY2019/cs7643_spring/assets/project_webpage_template/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction / Background / Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5 points) What did you try to do? What problem did you try to solve? Articulate your objectives using absolutely no jargon.\n",
    "#### The goal of this project is to understand the Transformer model, reproduce the paper's results and try to provide some food for thoughts on what to improve.\n",
    "\n",
    "(5 points) How is it done today, and what are the limits of current practice?\n",
    "#### The training mentioned in the paper was done on several GPU (?give their specs?).\n",
    "\n",
    "(5 points) Who cares? If you are successful, what difference will it make?\n",
    "#### Improvements on the Transformer model, and more generally the Attention mechanism, would benefit the entire research community that works on Natural Language Processing, both for theoretical and applied research.\n",
    "#### We managed to get close to the original paper's results with limited hardware and time. This project then proves the accessibility of such a complex model (?to finish?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10 points) What did you do exactly? How did you solve the problem? Why did you think it would be successful? Is anything new in your approach?\n",
    "#### After implementing the entire model, we made sure every building block was properly connected to the others by trying a simple task: copy. Indeed, a working implementation a such a heavy model should have no problem copying inputs to outputs.\n",
    "#### That being done, we thought about how we could reproduce the original paper's results without having access to the computational power the authors had. When plotting the distribution of the dataset's sequences length (?show distribution curve?), we observe that 90% of the sequences has a length of maximum 40 (the largest sequence having a length of 102). This helped making the training faster without harming the results too much.\n",
    "#### (?complete?)\n",
    "\n",
    "(5 points) What problems did you anticipate? What problems did you encounter? Did the very first thing you tried work?\n",
    "#### (?talk about the difference of workflow between training and testing?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10 points) How did you measure success? What experiments were used? What were the results, both quantitative and qualitative? Did you succeed? Did you fail? Why?\n",
    "\n",
    "#### On a quantitative point of view, the loss (for both training and validation) is a good indicator of how well the model does; we used KL-divergence.\n",
    "#### (?show Tensorboard plots?)\n",
    "#### (?show visuals from poster?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In addition, 20 more points will be distributed based on presentation quality and Deep Learning knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5 points) Appropriate use of visual aids. Are the ideas presented with appropriate illustration? Is the problem effectively visualized? Is the approach visualized appropriately? Are the results presented clearly; are the important differences illustrated? Every section and idea does not need a visual aid, but the most interesting and complex parts of the project should be illustrated.\n",
    "\n",
    "(5 points) Overall clarity. Is the presentation clear? Can a peer who has also taken Deep Learning understand all of the points addressed above? Is sufficient detail provided?\n",
    "\n",
    "(10 points) Finally, points will be distributed based on your understanding of how your project relates to Deep Learning. Here are some questions to think about:\n",
    "\n",
    "- What was the structure of your problem? How did the structure of your model reflect the structure of your problem?\n",
    "- What parts of your model had learned parameters (e.g., convolution layers) and what parts did not (e.g., post-processing classifier probabilities into decisions)?\n",
    "- What representations of input and output did the neural network expect? How was the data pre/post-processed?\n",
    "What was the loss function?\n",
    "- Did the model overfit? How well did the approach generalize?\n",
    "- What hyperparameters did the model have? How were they chosen? How did they affect performance? What optimizer was used?\n",
    "- What Deep Learning framework did you use?\n",
    "- What existing code or models did you start with and what did those starting points provide?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
